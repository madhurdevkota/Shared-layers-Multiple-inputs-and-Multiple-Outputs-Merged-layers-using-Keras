{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq4HK0pjbRI0"
   },
   "source": [
    "<h2>Two Input Networks Using Categorical Embeddings, Shared Layers, & Merge Layers\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as klyr\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "pd.set_option( 'display.max_rows', 8 )\n",
    "pd.set_option( 'display.max_columns', None )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5X-H_8fbRI0"
   },
   "source": [
    "<h3>Category Embeddings</h3>\n",
    "\n",
    "`Category Embedding` are advanced NN layer function, used for dealing with high cadinality cateogrical data.\n",
    "\n",
    "###### Define team model\n",
    "\n",
    "The team strength lookup has 3 components:\n",
    "- an input\n",
    "- an embedding layer and\n",
    "- a flatten layer that creates the output.\n",
    "\n",
    "If we wrap these 3 layers in a model with an input & output, we can re-use that stack of 3 layers at multiple places.\n",
    "\n",
    "Note again that the weights for all 3 layers will be shared everywhere we use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgame_df = pd.read_csv( r'datasets\\games_season.csv' )\n",
    "print( sgame_df.shape );  sgame_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgame_df['team_1'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding layer that maps each team ID to a single number representing that team's strength.\n",
    "embedLyr = klyr.Embedding(   input_dim= sgame_df['team_1'].nunique(), input_length= 1,  # each team is represented as a single integer, use an input length of 1\n",
    "                             output_dim= 1,  # to produce a single team strength rating use an output dimension of 1\n",
    "                             name= 'team-strength-embedding-model'   )\n",
    "# The input length should be 1 dimension (as each team is represented by exactly one id)\n",
    "# The output shape should be 1 dimension (as we want to represent the teams by a single number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1D input tensor layer for the team ID (which will be an integer)\n",
    "inputTnsr = klyr.Input(  shape= ( 1, )  )\n",
    "# Pass this input tensor to the embededLyr Team lookup layer that was created previously\n",
    "embTnsr = embedLyr( inputTnsr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding layers increase the dim of the data. The input CSV has two dimensions (rows & columns),\n",
    "# but embedding layers add a 3rd dim. This 3rd dim is useful when dealing with images and text, so it is not as relevant for this dataset.\n",
    "# Therefore, we use the flatten layer to flatten the embeddings from 3D to 2D.\n",
    "y_embTnsr_flat = klyr.Flatten()( embTnsr )\n",
    "\n",
    "print( f'embTnsr --> {embTnsr.shape}  \\n\\ny_embTnsr_flat --> {y_embTnsr_flat.shape}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all steps (repeatative)\n",
    "inputTnsr = klyr.Input(  shape= ( 1, )  )\n",
    "embedLyr = klyr.Embedding(   input_dim= sgame_df['team_1'].nunique(), input_length= 1,  output_dim= 1, name= 'team-strength-embedding-model'   )\n",
    "embTnsr = embedLyr( inputTnsr )\n",
    "y_embTnsr_flat = klyr.Flatten()( embTnsr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kModel1 = keras.Model(  inputs= inputTnsr, outputs= y_embTnsr_flat )\n",
    "kModel1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsWBgi4QbRI1"
   },
   "outputs": [],
   "source": [
    "## all at once (repeated)\n",
    "inputTnsr = klyr.Input( shape= (1,) )\n",
    "embedFuncLyr = klyr.Embedding(   input_dim= sgame_df['team_1'].nunique(), input_length= 1,  # each team is represented as a single integer, use an input length of 1\n",
    "                             output_dim= 1,  # to produce a single team strength rating use an output dimension of 1\n",
    "                             name= 'team-strength-embedding-lyr'\n",
    "                         )\n",
    "y_embTnsr = embedFuncLyr( inputTnsr )\n",
    "y_embTnsr_flat = klyr.Flatten()( y_embTnsr )\n",
    "\n",
    "kModel1 = keras.Model(  inputs= inputTnsr, outputs= y_embTnsr_flat, name= 'team-strength-embedding-model'  )\n",
    "\n",
    "kModel1.summary()\n",
    "keras.utils.plot_model( kModel1, show_shapes= True,  show_layer_activations= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model( kModel1, show_shapes= True,  show_layer_activations= True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Category Embeddings for AirBnB data\n",
    "\n",
    "\n",
    "`Categorical entity embedding` extracts the embedding layers of categorical variables from a neural network model, and uses numeric vectors to represent the properties of the categorical values. It is usually used on categorical variables with high cardinalities. \n",
    "\n",
    "For example, a marketing company can create categorical entity embedding for different campaigns to represent the characteristics using vectors, and use those vectors to understand the similarities between campaigns, or put the vectors as features into different machine learning models to improve the model performance.\n",
    "\n",
    "Here we are using Tensorflow Keras to create categorical entity embeddings of Airbnb neighbourhood data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "##### Data download\n",
    "\n",
    "A website called Inside Airbnb had the Airbnb data publicly available for research. We used the listing data for Washington D.C. for this analysis.\n",
    "\n",
    "Download the data:\n",
    "1. Go to: http://insideairbnb.com/get-the-data\n",
    "2. Scroll down the page until you see the section called **Washington, D.C., District of Columbia, United States**. \n",
    "3. Click the blue file name \"listings.csv\" to download the data.\n",
    "\n",
    "The listing data has the property information aggregated at the listing ID level. We will build a simple model to predict the listing price, and the following columns will be read from the dataset.\n",
    "* `id` is the unique ID for the Airbnb listing.\n",
    "* `neighbourhood` is the neighbourhood name where the listing is located.\n",
    "* `room_type` is the type of the room. It can be the entire house, a room in a house, etc.\n",
    "* `price` is the daily price in local currency. Washington D.C. is in the United States, so the currency for the price is US dollars.\n",
    "* `minimum_nights` is the listing's minimum number of nights for the stay.\n",
    "* `number_of_reviews` is the total number of reviews for the listing.\n",
    "* `reviews_per_month` is the average number of reviews per month.\n",
    "* `calculated_host_listings_count` is the total number of listings that the host has in Washington D.C.\n",
    "* `availability_365` is the availability of the listing in the next 365 days. The listing can be unavailable because of the guest booking or the host blocking.\n",
    "* `number_of_reviews_ltm` is the number of reviews in the last 12 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of concerned columns \n",
    "cols_to_keep = [  'id', 'neighbourhood', 'room_type', 'price',  'minimum_nights',  'number_of_reviews', \n",
    "                  'reviews_per_month', 'calculated_host_listings_count', 'availability_365', 'number_of_reviews_ltm'  ]\n",
    "air_df = pd.read_csv(  r'datasets\\airbnb_listings_dc_20020914.csv',\n",
    "                          usecols= cols_to_keep )\n",
    "\n",
    "air_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider `neighbourhood` as Categorical. Then, we can say that, 2 out of the 10 columns are categorical i.e. `neighbourhood` & `room_type`. Most of the columns do not have missing data. Only the variable `reviews_per_month` has missing data and needs missing imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_df[ air_df['reviews_per_month'].isnull() ]['number_of_reviews'].value_counts()\n",
    "'''\n",
    "We can see that all the listings with missing values have zero reviews. Therefore, we need to impute the missing values to zeros.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values for reviews_per_month to 0\n",
    "air_df['reviews_per_month'] = air_df['reviews_per_month'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(  f'The minimum price is {air_df.price.min()} and the maximum price is {air_df.price.max()}.'  )\n",
    "# The price range shows that the minimum price is 0 and the maximum price is 10,000.\n",
    "# let's remove the outlier prices and only keep the listings with a daily price greater than 20 dollars and less than 1000 dollars.\n",
    "air_df = air_df[  (air_df['price']>20) & (air_df['price']<1000) ].reset_index( drop= True )\n",
    "print(  f'The minimum price is {air_df.price.min()} and the maximum price is {air_df.price.max()}.'  )\n",
    "air_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.style.use( 'dark_background'  )\n",
    "sns.displot(  air_df['price'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_df['room_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_df['room_type'] = air_df['room_type'].astype( 'category' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# room_type categories\n",
    "ax = sns.countplot( data= air_df, x= 'room_type' )\n",
    "ax.bar_label( ax.containers[0] ) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the number of categories is small for `room_type`, we will not do entity embeddings.\n",
    "# Instead, we will use `get_dummies` to create a dummy variable with 0 & 1 values for each category.\n",
    "air_df = (  air_df\n",
    "     .pipe(    lambda df: df.assign(   room_type = df['room_type'].replace(  { 'Private room':'private', 'Entire home/apt':'entireUnit', 'Shared room':'sharedRoom', 'Hotel room':'hotelRoom' }  )   )    )\n",
    "     .pipe(    lambda df: pd.concat(  [ df, pd.get_dummies( df['room_type'] ) ], axis= 'columns'   )    )\n",
    "     .drop( columns= 'room_type', errors= 'ignore' )\n",
    ")\n",
    "air_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neighborhood distribution\n",
    "fg, ax = plt.subplots( 1,1, figsize= (20, 7) )\n",
    "sns.countplot(  data= air_df, x= 'neighbourhood', order= air_df['neighbourhood'].value_counts().index, ax= ax  )\n",
    "# Add labels\n",
    "ax.bar_label( ax.containers[0] )\n",
    "# Rotate x labels\n",
    "ax.tick_params(  axis= 'x', rotation= 75  )  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train test split\n",
    "* `x` has all the features for the model prediction.\n",
    "* `y` is the target variable. We are predicting the daily listing prices, so the column `price` is used as the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "xtrn, xtst, ytrn, ytst = sklearn.model_selection.train_test_split(  air_df.drop( columns= [ 'id', 'price' ] ),\n",
    "                                      air_df['price'], test_size= 20./100, random_state= 42   )\n",
    "\n",
    "print(  f'''The training dataset has shape --> {xtrn.shape}\n",
    "The y label have shape --> {ytrn.shape}''' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `categorical label encoding` for the *`neighbourhood`* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catEncoder_dictn = {   eNeigh:idx  for idx, eNeigh in enumerate(  sorted(xtrn['neighbourhood'].unique())  )   }\n",
    "\n",
    "[  print( f'{eKey} : {eVal}' )  for eKey, eVal in catEncoder_dictn.items() if eVal < 5 ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn_NeighborMap_arr = xtrn['neighbourhood'].map( catEncoder_dictn ).values\n",
    "xtst_NeighborMap_arr = xtst['neighbourhood'].map( catEncoder_dictn ).values\n",
    "print( type(xtrn_NeighborMap_arr),'\\n\\n', xtrn_NeighborMap_arr, '\\n', xtst_NeighborMap_arr )\n",
    "\n",
    "'''we can observe that the list for the training and testing dataset now has arrays of numbers representing the neighbourhoods'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's build a model with categorical entity embedding.\n",
    "\n",
    "Firstly, let's create the embedding layer using the `Embedding` function.\n",
    "\n",
    "* `input_dim` is the number of unique values for the categorical column. In this example, it is the number of unique neighbourhood.\n",
    "* `output_dim` is the dimension of the embedding output. How to decide this number? The authors of the [entity embedding paper](https://arxiv.org/pdf/1604.06737.pdf) mentioned that it is a *hyperparameter* value to tune with the range of [1, no. of categories - 1]. The authors proposed 2 general guidelines:\n",
    "    * If the number of aspects to describe the entities can be estimated, we can use that as the `output_dim`. More complex entities usually need more output dimensions. For example, `neighbourhood` can be described by population density, distance to major tour locations, convenience level, number of Airbnb listings, and safety index, so we set 5 as the number of output dimensions.\n",
    "    * If the number of aspects to describe the entities cannot be estimated, then start with the highest possible number of dimensions, which = no. of categories - 1 for the hyperparameter tuning.\n",
    "* `name` gives a name for the layer.\n",
    "* The input dimension of the categorical variable is defined by the `Input` function. `Input()` is used to instantiate a Keras tensor. `shape=(1,)` indicates that the expected input will be a one-dimensional vector.\n",
    "* `Reshape` changed the output from 3-dimensional to 2-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = xtrn['neighbourhood'].nunique()\n",
    "output_dim = 5\n",
    "\n",
    "input_CatTnsr = klyr.Input( shape= (1,) )\n",
    "embed_catTnsr = klyr.Embedding(  input_dim= input_dim, output_dim= output_dim, name= 'embeddingLyr_location'  )( input_CatTnsr )\n",
    "embed_catTnsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten to reduce the dimension: `shape = (None, 1, 5)` --> `shape = (None, 5)`\n",
    "\n",
    "Embedding layers increase the dimensionality of the data. The xtrn has 2 dimensions (rows & columns), but embedding layers add a 3rd dimension. This 3rd  dimension can be useful when dealing with images & text, so it is not as relevant to our dataset. Therefore, we use the `flatten layer `to flatten the embeddings from 3D to 2D.\n",
    "\n",
    "The flatten layer is also the output layer for the embedding process. Flatten layers are an layer for deep learning models and can be used to transform data from multiple dimensions back down to 2 dimensions. They are useful for dealing with time series data, text data, & images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## either use Reshape OR Flatten\n",
    "# embed_catTnsr = klyr.Reshape(  target_shape= (output_dim, )  )( embed_catTnsr )\n",
    "# OR\n",
    "embed_catTnsr = klyr.Flatten()( embed_catTnsr )\n",
    "embed_catTnsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn.drop( columns= 'neighbourhood' ).values\n",
    "xtst.drop( columns= 'neighbourhood' ).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dim of the numeric features\n",
    "input_numTnsr = klyr.Input(   shape= ( xtrn.drop( columns= 'neighbourhood' ).shape[1],  )  )\n",
    "# output dim of the numeric features\n",
    "embed_numTnsr = input_numTnsr \n",
    "input_numTnsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTnsr = [ input_CatTnsr, input_numTnsr ]\n",
    "print( f'{inputTnsr}' )\n",
    "\n",
    "print('''\\nThe input Keras tensors for both the categorical and the numeric variables are put in a list called `inputTnsr`.\n",
    "`inputTnsr` shows that the first element has an input dimension of 1 and the second element has an input dimension of 10.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the output Keras tensors for both the categorical and the numeric variables are put in a list called `emb_data`. `emb_data` shows that the first element has an output dimension of 5 and the second element has an output dimension of 10.\n",
    "* The categorical variable `neighbourhood` has a dimension of 5 because we manually specified the embedding dimension to be 5 in the embedding layer.\n",
    "* The numeric variables have a dimension of 10 because there are 10 numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embTnsr = [  embed_catTnsr, embed_numTnsr  ]\n",
    "print( f'{embTnsr}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the `Concatenate()` function, the Keras tensors in the list `emb_data` are concatenated together.\n",
    "# The output Keras tensor has a dimension of 15, which is the sum of the dimension of the two tensors in the list.\n",
    "modelInputTnsr = klyr.Concatenate()( embTnsr )\n",
    "modelInputTnsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared layers\n",
    "\n",
    "Shared layers allow to define an operation and then apply the exact same operation (with the exact same weights) on different inputs.\n",
    "\n",
    "In this model, we will share team rating for both inputs. The learned rating will be the same, whether it applies to team 1 or team 2.\n",
    "\n",
    "<h3><p style= text-align:left;'>Shared Layer</p></h3>\n",
    "<img src= 'images/shared_lyr.jpg' style= 'width:512px;height:297px;'>\n",
    "<!-- # m, wd, ht = 2, 990, 576; ( wd/m, ht/m  ) -->\n",
    "\n",
    "[Go to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input tensr lyrs\n",
    "inputTnsr1 = klyr.Input( shape= (1,), name= 'inputLyr_team1' )\n",
    "inputTnsr2 = klyr.Input( shape= (1,), name= 'inputLyr_team2' )\n",
    "\n",
    "## Dense layr (to be shared by multiple inputs)\n",
    "denseFuncLyr = klyr.Dense( units= 1 )\n",
    "\n",
    "# y output Tensor\n",
    "y_Tnsr1 = denseFuncLyr( inputTnsr1 )\n",
    "y_Tnsr2 = denseFuncLyr( inputTnsr2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id= '6.2.5'>\n",
    "</div>\n",
    "\n",
    "### 6.2.5 Shared Model\n",
    "\n",
    "Sharing multiple layers as a model\n",
    "\n",
    "Using Keras API, we can also share models, not just layers. \n",
    "We can share the previously designed `category embedding model` where the model first embeds an input and then flattens it.\n",
    "\n",
    "We can define modular components of models and then reuse them. We define an embedding layer and wrap it in a model. We then define 2 input tensors, and pass each one to the same model, producing 2 output tensors. This will use the same model, with the same layers and the same weights, for mapping each input to its corresponding output.\n",
    "\n",
    "In other words, we can take an arbitrary sequence of keras layers, and wrap them up in a model. Once we have a model, we can re-use that model to share that sequence of steps for different input layers. \n",
    "\n",
    "<h3><p style= text-align:left;'>Shared Model</p></h3>\n",
    "<img src= 'images/shared_model.jpg' style= 'width:516px;height:325px;'>\n",
    "<!-- m, wd, ht = 2, 990, 576; ( wd/m, ht/m  ) -->\n",
    "\n",
    "[Go to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model to be shared later\n",
    "inputTnsr = klyr.Input( shape= (1,) )\n",
    "embedFuncLyr = klyr.Embedding(   input_dim= sgame_df['team_1'].nunique(), input_length= 1,  # each team is represented as a single integer, use an input length of 1\n",
    "                                 output_dim= 1,  # to produce a single team strength rating use an output dimension of 1\n",
    "                                 name= 'teamStrength_embdLyr'\n",
    "                             )\n",
    "y_embTnsr = klyr.Flatten()( embedFuncLyr( inputTnsr ) )\n",
    "\n",
    "kEmbTeamStrength_model = keras.Model(  inputs= inputTnsr, outputs= y_embTnsr, name= 'teamStrength_embdModel'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kEmbTeamStrength_model.summary(); keras.utils.plot_model( kEmbTeamStrength_model, show_shapes= True,  show_layer_activations= True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookup both inputs in the same model\n",
    "\n",
    "Now that we have a team strength model (`kEmbTeamStrength_model`) and an input layer for each team, we can lookup the team inputs in the shared team strength model. The two inputs will share the same weights.\n",
    "\n",
    "This dataset have 10,888 unique teams. We want to learn a strength rating for each team, such that if any pair of teams plays each other, we can predict the score, even if those two teams have never played before. Furthermore, we want the strength rating to be the same, regardless of whether the team is the home team or the away team.\n",
    "\n",
    "To achieve this, we use a shared layer, defined by the re-usable model (`kEmbTeamStrength_model()`) and the two input layers (`inputTnsr1` & `inputTnsr2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input tensr lyrs for team 1 & 2 resp\n",
    "inputTnsr1 = klyr.Input( shape= (1,), name= 'inputLyr_team1' )\n",
    "inputTnsr2 = klyr.Input( shape= (1,), name= 'inputLyr_team2' )\n",
    "\n",
    "## use the kEmbTeamStrength_model for both teams inputs\n",
    "team1_Tnsr =  kEmbTeamStrength_model( inputTnsr1 )\n",
    "team2_Tnsr =  kEmbTeamStrength_model( inputTnsr2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Merge Tensors, Merge layers made from Shared Model\n",
    "\n",
    "#### Add, Substract, multiply, Concatenate the input Tensor frames\n",
    "Now that we've got multiple inputs & a shared layer, we need to combine the inputs into a single layer that we can use to predict a single output. This requires a `Merge layer`. `Merge layers` allow to define advanced, *non-sequential network topologies*. This can give a Data Scientist a lot of flexibility to creatively design networks to solve specific problems. \n",
    "\n",
    "<h3><p style= text-align:left;'>Merge Model</p></h3>\n",
    "<img src= 'images/merge_lyrs.png' style= 'width:837px;height:450px;'>\n",
    "<!-- m, wd, ht = 2, 990, 576; ( wd/m, ht/m  ) -->\n",
    "\n",
    "[Go to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model to be shared later (repeat)\n",
    "inputGeneralTnsr = klyr.Input( shape= (1,), name= 'GeneralInputTnsr' )\n",
    "embedFuncLyr = klyr.Embedding(   input_dim= sgame_df['team_1'].nunique(), input_length= 1,  # each team is represented as a single integer, use an input length of 1\n",
    "                                 output_dim= 1,  # to produce a single team strength rating use an output dimension of 1\n",
    "                                 name= 'teamStrength_embdLyr'\n",
    "                             )\n",
    "y_embTnsr = embedFuncLyr( inputGeneralTnsr )\n",
    "y_embTnsr_flat = klyr.Flatten()( y_embTnsr )\n",
    "\n",
    "kEmbTeamStrength_model = keras.Model(  inputs= inputGeneralTnsr, outputs= y_embTnsr_flat, name= 'kEmbTeamStrength_model'  )\n",
    "# kEmbTeamStrength_model.summary(); keras.utils.plot_model( kEmbTeamStrength_model, show_shapes= True,  show_layer_activations= True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The tensors to be merged should have compatible shapes.<br>\n",
    "For example for adding, the shape cannot be (5,) and (6,)<br>\n",
    "Then you get : ValueError: Inputs have incompatible shapes. Received shapes (5,) and (6,)<br>\n",
    "\n",
    "<h3><p style= text-align:left;'>Merge Layers</p></h3>\n",
    "<img src= 'images/merge_lyrs.png' style= 'width:837px;height:450px;'>\n",
    "<!-- m, wd, ht = 2, 990, 576; ( wd/m, ht/m  ) -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input tensr lyrs for team 1 & 2 resp\n",
    "inputTeam1Tnsr1 = klyr.Input( shape= (1,), name= 'inputLyr_team1' )\n",
    "inputTeam2Tnsr2 = klyr.Input( shape= (1,), name= 'inputLyr_team2' )\n",
    "\n",
    "embTeamStrength_Tnsr1 = kEmbTeamStrength_model( inputTeam1Tnsr1 )\n",
    "embTeamStrength_Tnsr2 = kEmbTeamStrength_model( inputTeam2Tnsr2 )\n",
    "\n",
    "# Create a subtract layer using the inputs from the our team dataset\n",
    "scoreDiff_yTnsr = klyr.Subtract( )( [ embTeamStrength_Tnsr1, embTeamStrength_Tnsr2 ] )\n",
    "scoreDiff_yTnsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model using two inputs and one output\n",
    "\n",
    "Now that we have two inputs (team id 1 and team id 2) and output (scoreDiff_Tnsr), we can wrap them up in a model so we can use it later for fitting to data and evaluating on new data.\n",
    "\n",
    "The model will look like the following diagram:\n",
    "\n",
    "<h3><p style= text-align:left;'>Shared Model</p></h3>\n",
    "<img src= 'images/basketball_model_2.png' style= 'width:415px;height:255px;'>\n",
    "<!-- m, wd, ht = 2, 990, 576; ( wd/m, ht/m  ) -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model to be shared later ## repeated for clarity\n",
    "inputGeneralTnsr = klyr.Input( shape= (1,), name= 'GeneralInputTnsr' )\n",
    "embedFuncLyr = klyr.Embedding(   input_dim= sgame_df['team_1'].nunique(), input_length= 1,  # each team is represented as a single integer, use an input length of 1\n",
    "                                 output_dim= 1,  # to produce a single team strength rating use an output dimension of 1\n",
    "                                 name= 'teamStrength_embdLyr'\n",
    "                             )\n",
    "y_embTnsr = embedFuncLyr( inputGeneralTnsr )\n",
    "y_embTnsr_flat = klyr.Flatten()( y_embTnsr )\n",
    "kEmbTeamStrength_model = keras.Model(  inputs= inputGeneralTnsr, outputs= y_embTnsr_flat, name= 'kEmbTeamStrength_model'  )\n",
    "# kEmbTeamStrength_model.summary(); keras.utils.plot_model( kEmbTeamStrength_model, show_shapes= True,  show_layer_activations= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## repeated for clarity\n",
    "## input tensr lyrs for team 1 & 2 resp\n",
    "inputTeam1Tnsr1 = klyr.Input( shape= (1,), name= 'inputLyr_team1' )\n",
    "inputTeam2Tnsr2 = klyr.Input( shape= (1,), name= 'inputLyr_team2' )\n",
    "embTeamStrength_Tnsr1 = kEmbTeamStrength_model( inputTeam1Tnsr1 )\n",
    "embTeamStrength_Tnsr2 = kEmbTeamStrength_model( inputTeam2Tnsr2)\n",
    "# Create a subtract layer using the inputs from the our team dataset\n",
    "scoreDiff_yTnsr = klyr.Subtract( name= 'scoreDiff_yTnsr' )( [ embTeamStrength_Tnsr1, embTeamStrength_Tnsr2 ] )\n",
    "\n",
    "## new from here\n",
    "## create the model\n",
    "kSharedMerged_model = keras.models.Model(  inputs=  [ inputTeam1Tnsr1, inputTeam2Tnsr2 ], outputs= scoreDiff_yTnsr,\n",
    "                                           name= 'kSharedMerged_model'  )\n",
    "\n",
    "kSharedMerged_model.compile(  optimizer= 'adam', loss= 'mean_absolute_error'  )\n",
    "kSharedMerged_model.summary(); keras.utils.plot_model( kSharedMerged_model, show_shapes= True,  show_layer_activations= True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><p style= text-align:left;'>Keras - Shared --> Merged --> Model</p></h3>\n",
    "<img src= 'images/keras-sharedMerged-models.jpg' style= 'width:1703px;height:334px;'>\n",
    "<!-- m, wd, ht = 2, 990, 576; ( wd/m, ht/m  ) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id= '6.2.7'>\n",
    "</div>\n",
    "\n",
    "### 6.2.7 Predict from shared merged model\n",
    "\n",
    "Key Concepts\n",
    "\n",
    "    Keras models can handle multiple inputs, similar to single-input models.\n",
    "    The fit, evaluate, and predict methods work the same for both multiple and single-input models.\n",
    "    Multiple inputs require providing lists of inputs instead of single inputs.\n",
    "\n",
    "Fitting with Multiple Inputs\n",
    "\n",
    "    Provide a list of inputs with a length matching the number of model inputs.\n",
    "    In our example, maintain a single target for training, even with multiple inputs.\n",
    "\n",
    "Predicting with Multiple Inputs\n",
    "\n",
    "    Convert input values to 2D NumPy arrays.\n",
    "    Pass the input list to the model's predict() method.\n",
    "    The model outputs the predicted result.\n",
    "\n",
    "Evaluating with Multiple Inputs\n",
    "\n",
    "    Provide a list of inputs and a single output.\n",
    "\n",
    "[Go to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgame_df = pd.read_csv( 'datasets/games_season.csv' )\n",
    "print( sgame_df.shape );  sgame_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kSharedMerged_model_fitHist =  kSharedMerged_model.fit(  x= [ sgame_df['team_1'], sgame_df['team_2'] ],\n",
    "                                                         y= sgame_df['score_diff'],\n",
    "                                                         epochs= 300, batch_size= 2048, validation_split=10./100, verbose= 2   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use( 'dark_background' )\n",
    "from utils import utils_data_analytics as u_da\n",
    "# u_da.plot_model_loss( kSharedMerged_model_fitHist )\n",
    "plot_model_loss( kSharedMerged_model_fitHist )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Two Input Networks Using Categorical Embeddings, Shared Layers, & Merge Layers\n",
    "\n",
    "\n",
    "### Three - Input model\n",
    "Building and Training 3-Input Models with Keras\n",
    "\n",
    "    Creating a 3-Input Model:\n",
    "        Define 3 separate input layers.\n",
    "        Utilize a Concatenate layer to merge the inputs.\n",
    "        Employ a Dense layer to reduce the 3 inputs to 1 output.\n",
    "\n",
    "    Incorporating Shared Layers in 3-Input Models:\n",
    "        Pass the first two inputs to a shared layer.\n",
    "        Concatenate the output of the shared layer with the third input.\n",
    "\n",
    "    Fitting and Evaluating 3-Input Models:\n",
    "        Compile the model with a loss function and an optimizer.\n",
    "        Provide a list of three input columns and one output during fitting.\n",
    "        Supply three inputs in a list and one output when evaluating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input tnsr lyrs for team 1 & 2 resp\n",
    "inputTeam1Tnsr1 = klyr.Input(  shape= (1,), name= 'inputLyr_team1'  )\n",
    "inputTeam1Tnsr2 = klyr.Input(  shape= (1,), name= 'inputLyr_team2'  )\n",
    "# input tnsr for home vs away\n",
    "inputHomeTnsr = klyr.Input(  shape= (1,), name= 'inputLyr_home'  )\n",
    "# Lookup the team inputs in the kEmbTeamStrength_model\n",
    "embTeamStrength_Tnsr1 = kEmbTeamStrength_model( inputTeam1Tnsr1 )\n",
    "embTeamStrength_Tnsr2 = kEmbTeamStrength_model( inputTeam1Tnsr2 )\n",
    "# Combine the team strengths tnsrs with the home input tnsr using a Concatenate layer, then add a Dense layer\n",
    "yTnsr_concat = klyr.Concatenate()(  [ inputTeam1Tnsr1, inputTeam1Tnsr2, inputHomeTnsr ]  )\n",
    "yTnsr = klyr.Dense(1)( yTnsr_concat )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><p style= text-align:left;'>Concat Layers</p></h3>\n",
    "<img src= 'images/concat_Tnsr_lyrs.png' style= 'width:1490px;height:379px;'>\n",
    "<!-- m, wd, ht = 2, 2980, 758; ( wd/m, ht/m  ) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kSharedMergedConcat_model = keras.models.Model(  inputs= [ inputTeam1Tnsr1, inputTeam1Tnsr2, inputHomeTnsr],\n",
    "                                                 outputs= yTnsr  )\n",
    "kSharedMergedConcat_model.compile( optimizer= 'adam', loss= 'mean_absolute_error' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kEmbTeamStrength_model.summary()\n",
    "keras.utils.plot_model( kEmbTeamStrength_model, show_shapes= True, show_layer_activations= True, expand_nested= True, rankdir='LR',\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kSharedMergedConcat_model.summary();\n",
    "keras.utils.plot_model( kSharedMergedConcat_model, show_shapes= True, show_layer_activations= True, expand_nested= True, rankdir='LR',\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = [  sgame_df['team_1'], sgame_df['team_2'], sgame_df['home']  ]\n",
    "kSharedMergedConcat_modelHist = \\\n",
    "    kSharedMergedConcat_model.fit(  x= xx, y= sgame_df['score_diff'],\n",
    "                                    epochs= 400, verbose= 2, validation_split= 20./100, batch_size= 2048  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use( 'dark_background' )\n",
    "from utils import utils_data_analytics as u_da\n",
    "# u_da.plot_model_loss( kSharedMerged_model_fitHist )\n",
    "plot_model_loss( kSharedMergedConcat_modelHist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the games_tourney dataset\n",
    "print(\n",
    "kSharedMergedConcat_model.evaluate(  x= [ sgame_df['team_1'], sgame_df['team_2'], sgame_df['home'] ],\n",
    "                                     y= sgame_df['score_diff'], verbose= 2  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 312177\n",
    "kSharedMergedConcat_model.predict( x= [ sgame_df['team_1'].iloc[[i]], sgame_df['team_2'].iloc[[i]], sgame_df['home'].iloc[[i]] ] )\n",
    "y_ls = kSharedMergedConcat_model.predict( x= [ sgame_df['team_1'], sgame_df['team_2'], sgame_df['home'] ] )\n",
    "# sgame_df['team_1'].iloc[[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgame_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kSharedMergedConcat_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Multiple Outputs\n",
    "\n",
    "\n",
    "### Two output models\n",
    "\n",
    "Simple two-output model\n",
    "\n",
    "We will use the tournament data to build one model that makes two predictions: the scores of both teams in a given game. The inputs will be the seed difference of the two teams, as well as the predicted score difference from the model we built in last chapter.\n",
    "\n",
    "The output from the model will be the predicted score for team 1 as well as team 2. This is called `multiple target regression`: one model making more than one prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn, xtst, ytrn, ytst = sklearn.model_selection.train_test_split(  sgame_df.drop( columns= ['score_1', 'score_2'] ),\n",
    "                                                                    sgame_df[ ['score_1', 'score_2'] ],\n",
    "                                                                    test_size= 20./100, random_state= 10                 \n",
    "                         )\n",
    "print( f\"\"\"\n",
    "x -->  {xtrn.shape}\\n{xtrn.head(2)}\\n\\n\n",
    "y -->  {ytrn.shape}\\n{ytrn.head(2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipTnsr = klyr.Input(  shape= (xtrn.shape[-1],)  )\n",
    "denseLyr1 = klyr.Dense( 500 )( ipTnsr )\n",
    "denseLyr2 = klyr.Dense( 250 )( denseLyr1 )\n",
    "denseLyr3 = klyr.Dense( 100 )( denseLyr2 )\n",
    "denseLyr4 = klyr.Dense( 50 )( denseLyr3 )\n",
    "denseLyr5 = klyr.Dense( 25 )( denseLyr4 )\n",
    "denseLyr6 = klyr.Dense( 10 )( denseLyr5 )\n",
    "denseLyr7 = klyr.Dense( 5 )( denseLyr6 )\n",
    "opTnsr = klyr.Dense( 2 )( denseLyr7 )\n",
    "\n",
    "regModel = keras.models.Model( inputs= ipTnsr, outputs= opTnsr )\n",
    "regModel.compile( optimizer= 'adam', loss= 'mean_squared_error' )\n",
    "regModel.fit(  x= xtrn, y= ytrn, epochs= 25, batch_size= 16384, verbose= 2, validation_data= (xtst, ytst)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plots for losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, ax = plt.subplots( 1,2, figsize= (15, 4) )\n",
    "\n",
    "loss_df = pd.DataFrame( regModel.history.history )\n",
    "loss_df[ ['loss','val_loss'] ].plot( ax= ax[0] )\n",
    "loss_df.loc[ loss_df['loss']<=150, ['loss','val_loss'] ].plot( ax= ax[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_tst = pd.DataFrame( regModel.predict( xtst ), columns=  ytst.columns )\n",
    "yhat_ytst = pd.concat(  [ yhat_tst, ytst.reset_index(drop=True) ], axis= 1 )\n",
    "yhat_ytst.columns= [ 'yhat_s1', 'yhat_s2', 'ytst_s1', 'ytst_s2' ]\n",
    "yhat_ytst.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, ax = plt.subplots( 3,2, figsize= (20, 12) )\n",
    "\n",
    "yhat_tst_sample1 = yhat_ytst.sample( frac= 0.04/100, random_state= 10 ).reset_index(drop=True)\n",
    "yhat_tst_sample2 = yhat_ytst.sample( frac= 0.04/100, random_state= 20 ).reset_index(drop=True)\n",
    "yhat_tst_sample3 = yhat_ytst.sample( frac= 0.04/100, random_state= 30 ).reset_index(drop=True)\n",
    "\n",
    "yhat_tst_sample1[ ['yhat_s1','ytst_s1'] ].plot( ax= ax[0][0], color= ('teal', 'gray') )\n",
    "yhat_tst_sample1[ ['yhat_s2','ytst_s2'] ].plot( ax= ax[0][1], color= ('teal', 'gray') )\n",
    "\n",
    "yhat_tst_sample2[ ['yhat_s1','ytst_s1'] ].plot( ax= ax[1][0], color= ('teal', 'gray') )\n",
    "yhat_tst_sample2[ ['yhat_s2','ytst_s2'] ].plot( ax= ax[1][1], color= ('teal', 'gray') )\n",
    "\n",
    "yhat_tst_sample3[ ['yhat_s1','ytst_s1'] ].plot( ax= ax[2][0], color= ('teal', 'gray') )\n",
    "yhat_tst_sample3[ ['yhat_s2','ytst_s2'] ].plot( ax= ax[2][1], color= ('teal', 'gray') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df['loss'].min(), regModel.evaluate( xtst, ytst )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### Single model for `Regression` & `Classification`\n",
    "\n",
    "[Go to top](#toc)\n",
    "\n",
    "When building a simple model for Classification & Regression\n",
    "\n",
    "        The model has two outputs: a regression output & a classification output.\n",
    "        The regression output predicts --> score difference between the two teams.\n",
    "        The classification output predicts --> whether or not team 1 will win the game.\n",
    "        \n",
    "Make a regressor/classifier model\n",
    "\n",
    "        The regression part of the model is a Dense layer with a single unit.\n",
    "        The classification part of the model is a Dense layer with a `sigmoid activation` function.\n",
    "\n",
    "Fit the combination classifier/regressor\n",
    "\n",
    "        The regression output is trained using the score difference between the two teams.\n",
    "        The classification output is trained using whether or not team 1 won the game.\n",
    "\n",
    "Interpretating the model's weights (Regressor)\n",
    "\n",
    "        Assume the weight of the first layer is 1.3 and the bias is almost zero.\n",
    "        This means that a 1 unit change in the teams' seed difference yields about 1.3 additional points in their score difference.\n",
    "\n",
    "Interpretating the model's weights (Classifier)\n",
    "\n",
    "        Assume the weight of the final layer is 0.14 and the bias is 0.007.\n",
    "        This means that an expected score difference of 1 point is equal to an expected win probability of scipy.special.expit( 1*.14 + .007 ) = 0.54 = 54%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tour_df = pd.read_csv( 'datasets/games_tourney.csv' )\n",
    "print( tour_df.shape ); tour_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = tour_df[ ['season', 'team_1', 'team_2', 'home', 'seed_diff'] ]\n",
    "y_reg = tour_df[ ['score_diff'] ]\n",
    "y_class = tour_df[ ['won'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f\"\"\"\n",
    "x -->\\n{xx.head()}\\n\\n\n",
    "y_reg -->\\n{y_reg.head()}\\n\\n\n",
    "y_class -->\\n{y_class.head()}\n",
    "\"\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipTnsr = klyr.Input( shape= (xx.shape[-1],) )\n",
    "opTnsr_Reg = klyr.Dense(  1, activation= 'linear'  )( ipTnsr )\n",
    "opTnsr_Class = klyr.Dense(  1, activation= 'sigmoid'  )( opTnsr_Reg )\n",
    "\n",
    "model_RegClass = keras.models.Model(  inputs= ipTnsr, outputs= [ opTnsr_Reg, opTnsr_Class ]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RegClass.summary()\n",
    "keras.utils.plot_model( model_RegClass, show_shapes= True, show_layer_activations= True, expand_nested= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RegClass.compile(  loss= ['mean_absolute_error', 'binary_crossentropy'],\n",
    "                         optimizer= keras.optimizers.Adam(learning_rate=0.01)  )\n",
    "model_RegClass.fit(  x= xx, y= [ y_reg, y_class ], epochs= 1000, verbose= 2   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RegClass.history.history\n",
    "\n",
    "fg, ax = plt.subplots( 1,2, figsize= (15, 4) )\n",
    "\n",
    "loss_df = pd.DataFrame( model_RegClass.history.history )\n",
    "loss_df\n",
    "loss_df[ ['loss'] ].plot( ax= ax[0] )\n",
    "loss_df[ ['dense_35_loss'] ].plot( ax= ax[1] )\n",
    "loss_df[ ['dense_35_loss'] ].plot( ax= ax[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipTnsr = klyr.Input( shape= (xx.shape[-1],) )\n",
    "\n",
    "denseLyr1 = klyr.Dense( 500 )( ipTnsr )\n",
    "denseLyr2 = klyr.Dense( 100 )( denseLyr1 )\n",
    "denseLyr3 = klyr.Dense( 25 )( denseLyr2 )\n",
    "denseLyr4 = klyr.Dense( 10 )( denseLyr3 )\n",
    "denseLyr5 = klyr.Dense( 5 )( denseLyr4 )\n",
    "opTnsr_Reg = klyr.Dense(  1, activation= 'linear'  )( denseLyr5 )\n",
    "opTnsr_Class = klyr.Dense(  1, activation= 'sigmoid'  )( opTnsr_Reg )\n",
    "\n",
    "model_RegClass = keras.models.Model(  inputs= ipTnsr, outputs= [ opTnsr_Reg, opTnsr_Class ]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RegClass.summary()\n",
    "keras.utils.plot_model( model_RegClass, show_shapes= True, show_layer_activations= True, expand_nested= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RegClass.compile(  loss= ['mean_absolute_error', 'binary_crossentropy'],\n",
    "                         optimizer= keras.optimizers.Adam(learning_rate=0.01)  )\n",
    "model_RegClass.fit(  x= xx, y= [ y_reg, y_class ], epochs= 200, verbose= 2   )\n",
    "loss_df = pd.DataFrame( model_RegClass.history.history )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RegClass.history.history\n",
    "\n",
    "fg, ax = plt.subplots( 1,2, figsize= (15, 4) )\n",
    "\n",
    "loss_df.loc[ :, ['loss'] ].plot( ax= ax[0] )\n",
    "loss_df.iloc[ :, 1 ].plot( ax= ax[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(  model_RegClass.evaluate( x= xx, y= [y_reg,y_class] )  )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 233.317,
   "position": {
    "height": "40px",
    "left": "754px",
    "right": "20px",
    "top": "77px",
    "width": "719.7px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
